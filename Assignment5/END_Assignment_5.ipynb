{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END_Assignment_5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf96cda-aa31-418d-f416-53d98abfdf94"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  z = 1/(1 + np.exp(-x))\n",
        "  return z # write your code here\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  dz = sigmoid(y) * (1 - sigmoid(y))\n",
        "  #print((1 - sigmoid(y)))\n",
        "  #def sigmoid(x): # sigmoid function\n",
        "  return 1 /(1+np.exp(-x)) #REMOVE\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return y * (1 - y)\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return np.tanh(x)\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1 - y * y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzOY4Mqd79wv",
        "outputId": "8b4b71c5-17dd-4fc1-b57b-6138043d6f77"
      },
      "source": [
        "print(sigmoid(0))\n",
        "print(dsigmoid(0))\n",
        "print(tanh(0.25))\n",
        "print(dtanh(tanh(dsigmoid(sigmoid(0)))))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n",
            "0\n",
            "0.24491866240370913\n",
            "0.940014848806378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size # write your code here\n",
        "size_b = z_size # write your code here\n",
        "size_c = X_size # write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
        "\n",
        "    C = f * C_prev + i * C_bar\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
        "    h = o * tanh(C)\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D_xOn0nBS1w",
        "outputId": "ab606ae6-0d30-4a41-e4c4-36717816922a"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))\n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "print(C.shape)\n",
        "print(i.shape)\n",
        "print(y)\n",
        "print(\"+++++++\")\n",
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "(100, 1)\n",
            "(100, 1)\n",
            "[[0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]\n",
            " [0.01333333]]\n",
            "+++++++\n",
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "f2e5ea97-6ee1-46e2-f0c4-084178846500"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " far throat.\n",
            "\n",
            "Chinarid�\n",
            "\n",
            "The showel cast outbreaks offectionesy. Abouth officlly have been diagnosed with beine gets peec here and cold bese the virm peoted Souts. On Bured of resubno Unitear.\n",
            "\n",
            "She tre \n",
            "----\n",
            "iter 49900, loss 4.910809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}